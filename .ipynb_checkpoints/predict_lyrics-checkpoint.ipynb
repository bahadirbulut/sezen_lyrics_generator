{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "# !wget --no-check-certificate \\\n",
    "#     https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
    "#     -O /tmp/sonnets.txt\n",
    "data = open('sezen_lyrics.txt').read()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 110, 100)          874400    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 110, 300)          301200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 110, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4372)              441572    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8744)              38237512  \n",
      "=================================================================\n",
      "Total params: 40,015,084\n",
      "Trainable params: 40,015,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_v1')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akşam olur, yalnızlık çöker değil bana hasret bulunmaz bilirim yareme bir muhabbet getirdi der guz ürperir ışıksızım uçur dudaklarda söndür kalbim vuslatta oğlanlar kızlar geğirip şişer kapında yatmayan caf üzüm göğe sığmadım bitince yalnızım gözümü açtığımda kalmışım yanımda ailem ve birde mutlu geleli canım sulara bıraktığın bana değil kadar gelmiş gelmiyor artık gönül anam sitem anam varsa gibi yaşamak dediğin kara kaplıya kaydedin beni sevilmediğim evde kapalıyız evde mu hadi hadi düşman öldür gittin ki yok konur et gelmiyor evin mu hadi hadi düşman öldür beş asi evde yokuz oğlanlar kızlar geğirip şişer yapılır ki da allahaısmarladık duvarda emri meğer hep bizemi bak hayatı\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"akşam olur, yalnızlık çöker\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
